{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DEL DATASET UTILIZANDO FASTTEXT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del dataset de entrenamiento original, empleamos el 80% del mismo para entrenar usando FastText. Por usuario se arma una oración. La misma se compone de la etiqueta correspondiente al \"product_id\" del objeto comprado y de las \"palabras\". Cada palabra representa un evento de dicho usuario y las palabras no son otra cosa que los \"product_id\" de los objetos vistos (event_type=view). En el caso de los objetos buscados (event_type=search), la palabra correspondiente a cada evento de este tipo es la primera palabra del string de busqueda. El test se hace sobre el 20% del dataset restante. Se calcula el nDCG segun lo indicado en el ML Challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerias necesarias y cargamos los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos de training...\n",
      "Cargando datos de items...\n",
      "Comienza el entrenamiento...\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.sparse as sps\n",
    "\n",
    "url_item_data = \"https://meli-data-challenge.s3.amazonaws.com/2020/item_data.jl.gz\"\n",
    "url_train_data = \"https://meli-data-challenge.s3.amazonaws.com/2020/train_dataset.jl.gz\"\n",
    "print('Cargando datos de training...')\n",
    "train_data = []\n",
    "with urllib.request.urlopen(url_train_data) as handle:\n",
    "  gz = gzip.GzipFile(fileobj=handle)\n",
    "  for i, line in enumerate(gz):\n",
    "    train_data.append(json.loads(line.strip().decode('utf-8')))\n",
    "\n",
    "\n",
    "    \n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.user_history\n",
    "\n",
    "print('Cargando datos de items...')\n",
    "\n",
    "\n",
    "item_data = []\n",
    "with urllib.request.urlopen(url_item_data) as handle:\n",
    "  gz = gzip.GzipFile(fileobj=handle)\n",
    "  for i, line in enumerate(gz):\n",
    "    item_data.append(json.loads(line.strip().decode('utf-8')))\n",
    "\n",
    "item_df = pd.DataFrame(item_data)\n",
    "del train_data\n",
    "del item_data\n",
    "del gz\n",
    "print('Comienza el entrenamiento...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armamos las \"oraciones\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados los resultados previos donde vimos que más del 95% de los usuarios realizaban sus compras dentro de las 96hs previas al ultimo evento registrado, decidimos quedarnos con los eventos de las ultimas 96hs contando desde el ultimo evento registrado. Armamos entonces las oraciones con esos eventos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion=[]\n",
    "\n",
    "for row in train_df.itertuples():\n",
    "    item_label='__label__'+str(row.item_bought)\n",
    "    item=''\n",
    "    #for i in range(0,len(row.user_history)):\n",
    "    j=0   \n",
    "    for i in range(len(row.user_history)-1,-1,-1): #del evento final hacia el primer evento\n",
    "        \n",
    "        #Calculo los tiempos entre el ultimo evento y cada evento anterior hasta las 96hs. \n",
    "        \n",
    "        end_time=row.user_history[-1]['event_timestamp'][0:23]\n",
    "        #print(datetime.strptime(end_time,'%Y-%m-%dT%H:%M:%S.%f')\n",
    "        delta_time=datetime.strptime(end_time, '%Y-%m-%dT%H:%M:%S.%f')-datetime.strptime(row.user_history[i]['event_timestamp'][0:23], '%Y-%m-%dT%H:%M:%S.%f') \n",
    "        delta_time=delta_time/pd.Timedelta(hours=1)        \n",
    "        if delta_time<96 :\n",
    "           j=j+1 #numero de eventos dentro de las ultimas 96hs. \n",
    "    ini_event=len(row.user_history)-j # evento AHORA inicial de cada usuario\n",
    "    \n",
    "    for k in range(ini_event,len(row.user_history)): #del NUEVO evento inicial al evento final. \n",
    "        if row.user_history[i]['event_type']=='view': # asi accedo x ejemplo a la primera tupla de mi user_history que contiene toda la info de un evento. \n",
    "          item=str(((row.user_history)[i]['event_info']))+' '+item # Y asi al valor asociado a una key en particular. \n",
    "        else:\n",
    "           item=str(((row.user_history)[i]['event_info'])).split(sep=' ')[0].lower()+' '+item # Y asi al valor asociado a una key en particular.  \n",
    "    total_item=item_label+' '+item\n",
    "    oracion.append(total_item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las oraciones nos quedan, por ejemplo:  __label__1748830 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 1786148 \n"
     ]
    }
   ],
   "source": [
    "print('Las oraciones nos quedan, por ejemplo: ', oracion[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos con FastText. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el entrenamiento, luego de haber entrenado con los hiperparametros por default y obtener resultados no muy buenos, decidimos luego de varios intentos, optar por entrenar empleando una tasa de aprendizaje (lr) de 0.5 y utilizar 15 epocas (epochs). Eligiendo estos hiperparametros hemos logrado evitar el overfitting que ocurría con otros valores así como errores debido a tasas de aprendizaje muy altas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division del dataset.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test=train_test_split(oracion, test_size=0.20, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los dataset de entrenamiento y test en un formato aceptable para FastText\n",
    "\n",
    "with open('train_file_s&v_80_lr05_epch15_last_96hs.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for item in x_train:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('test_file_s&v_20_lr05_epch15_last_96hs.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for item in x_test:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo con los HP seleccionados. \n",
    "\n",
    "model2=fasttext.train_supervised(input='train_file_s&v_80_lr05_epch15_last_96hs.txt',lr=0.5,epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo. \n",
    "\n",
    "model2.save_model(\"model_fasttext_80_s&v_lr05_epch15_last_96hs.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# De la misma manera que se entrenó el modelo para las ultimas 96 hs tmb se entrenó el modelo\n",
    "# con todos los eventos y se guardó. En caso de querer cargar dicho modelo u otros modelos: \n",
    "\n",
    "#model2=fasttext.load_model('model_fasttext_80_s&v_lr05_epch15_last_96hs.bin')\n",
    "model3=fasttext.load_model('model_fasttext_s&v_80_lr05_epch15.bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeamos el/los modelo/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo de las ultimas 96hs, obtenemos que la Precision es de:  0.022959513646358815  y la Recall es de:  0.022959513646358815\n"
     ]
    }
   ],
   "source": [
    "metrics2=model2.test(\"test_file_s&v_20_lr05_epch15_last_96hs.txt\")\n",
    "\n",
    "print('Para el modelo de las ultimas 96hs, obtenemos que la Precision es de: ', metrics2[1], ' y la Recall es de: ', metrics2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo c/ todos los eventos, obtenemos que la Precision es de:  0.09639115250291036  y la Recall es de:  0.09639115250291036\n"
     ]
    }
   ],
   "source": [
    "# El modelo que incluye todos los eventos es testeado con un conjunto de test que incluye todos los eventos y que\n",
    "# fue creado en una instancia anterior. \n",
    "\n",
    "metrics3=model3.test(\"test_file_s&v_20_lr05_epch15.txt\") \n",
    "\n",
    "print('Para el modelo c/ todos los eventos, obtenemos que la Precision es de: ', metrics3[1], ' y la Recall es de: ', metrics3[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la precision y la recall resultan mucho mejor con el modelo que incluye todos los eventos. Sin embargo, es necesario chequear tmb la metrica nDCG para asegurarnos que no haya overfitting. \n",
    "\n",
    "Por otro lado, otros modelos fueron entrenados con anterioridad. A continuacion, se presentan las metricas de dichos intentos anteriores. \n",
    "* Empleando los HP x default e ignorando los eventos del tipo Search:\n",
    "\n",
    "Se obtenían una precision y una recall de P=0.01389, R=0.01389 \n",
    "\n",
    "* Igual al caso anterior pero incluyendo los eventos del tipo Search: \n",
    "\n",
    "Mejoraron las metricas mencionadas, alcanzando ambas un valor de: 0.01399\n",
    "\n",
    "* Ahora, modificando los parametros por default a los finalmente elegidos (lr=0.5, epochs=15), se obtuvieron los siguientes valores: \n",
    "\n",
    "p= 0.09693441986806364, r=0.09693441986806364. \n",
    "\n",
    "Modificar los HP mejoró las metricas en casi un 700%. \n",
    "\n",
    "DECIDIMOS QUEDARNOS CON ESTOS HP. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con todos los eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El calculo de nDCG para todos los eventos debe hacerse con los datasets de entrenamiento y de test que incluyan a todos los eventos. Este calculo fue realizado con anterioridad (de la misma manera que se verá a continuación) y los valores resultantes fueron:\n",
    "\n",
    "nDCG obtenido en datos de ENTRENAMIENTO: 0.7601697277065944\n",
    "nDCG obtenido en datos de TEST: 0.14587328260284207\n",
    "\n",
    "Luego, el modelo está overfitteando al conjunto de entrenamiento, de allí un valor de nDCG tan alto que no se reproduce en el conjunto de test. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con las ultimas 96hs.\n",
    "Se calcula nDCG para los datasets de entrenamiento y de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG obtenido en datos de ENTRENAMIENTO: 0.4253912812892881\n",
      "nDCG obtenido en datos de TEST: 0.05485672754797448\n"
     ]
    }
   ],
   "source": [
    "\n",
    "item_list = item_df['item_id'].tolist()\n",
    "domain_list = item_df['domain_id'].tolist()\n",
    "item_domain_dict = dict(zip(item_list, domain_list))\n",
    "\n",
    "true_bitem = []\n",
    "pred_y_fastt_model = []\n",
    "\n",
    "for row in x_train:\n",
    "  tb = int(row[:20].split(' ')[0][9:])\n",
    "  true_bitem.append(tb)\n",
    "\n",
    "  preds = []\n",
    "  model_preds = model2.predict(row.split(' ',1)[1],k=10)[0]\n",
    "  for pred in model_preds:\n",
    "    preds.append(int(pred[9:]))\n",
    "  pred_y_fastt_model.append(preds)\n",
    "\n",
    "#CALCULO DEL nDCG\n",
    "def ndcg(predictions,bitem):\n",
    "  ''' Dada una List de predictions, y un item comprado (int), devuelve el calculo de nDCG de la prediccion'''\n",
    "  best = 22.4246159748234\n",
    "  current = 0\n",
    "  bdom = item_domain_dict[bitem]\n",
    "  for i in range(1,11):\n",
    "    pred = predictions[i-1]\n",
    "    if pred == bitem:\n",
    "      gain = 12\n",
    "    elif item_domain_dict[pred] == bdom:\n",
    "      gain = 1\n",
    "    else:\n",
    "      gain = 0\n",
    "    current += (1/np.log(1+i)) * gain\n",
    "  return current/best \n",
    "\n",
    "# true_bitem = train_df.item_bought.tolist()\n",
    "ndcg_list = []\n",
    "for i in range(len(true_bitem)):\n",
    "  ndcg_list.append(ndcg(pred_y_fastt_model[i], true_bitem[i]))\n",
    "\n",
    "print('nDCG obtenido en datos de ENTRENAMIENTO:' , sum(ndcg_list) / len(ndcg_list))\n",
    "\n",
    "\n",
    "true_bitem = []\n",
    "pred_y_fastt_model = []\n",
    "\n",
    "for row in x_test:\n",
    "  tb = int(row[:20].split(' ')[0][9:])\n",
    "  true_bitem.append(tb)\n",
    "\n",
    "  preds = []\n",
    "  model_preds = model2.predict(row.split(' ',1)[1],k=10)[0]\n",
    "  for pred in model_preds:\n",
    "    preds.append(int(pred[9:]))\n",
    "  pred_y_fastt_model.append(preds)\n",
    "\n",
    "#CALCULO DEL nDCG\n",
    "def ndcg(predictions,bitem):\n",
    "  ''' Dada una List de predictions, y un item comprado (int), devuelve el calculo de nDCG de la prediccion'''\n",
    "  best = 22.4246159748234\n",
    "  current = 0\n",
    "  bdom = item_domain_dict[bitem]\n",
    "  for i in range(1,11):\n",
    "    pred = predictions[i-1]\n",
    "    if pred == bitem:\n",
    "      gain = 12\n",
    "    elif item_domain_dict[pred] == bdom:\n",
    "      gain = 1\n",
    "    else:\n",
    "      gain = 0\n",
    "    current += (1/np.log(1+i)) * gain\n",
    "  return current/best \n",
    "\n",
    "# true_bitem = train_df.item_bought.tolist()\n",
    "ndcg_list = []\n",
    "for i in range(len(true_bitem)):\n",
    "  ndcg_list.append(ndcg(pred_y_fastt_model[i], true_bitem[i]))\n",
    "\n",
    "print('nDCG obtenido en datos de TEST:' , sum(ndcg_list) / len(ndcg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente obtenemos los siguientes valores para nDCG:\n",
    "\n",
    "* Ultimas 96hs con lr=0.5 y 15 épocas:\n",
    "\n",
    "nDCG obtenido en datos de ENTRENAMIENTO: 0.43\n",
    "nDCG obtenido en datos de TEST: 0.05\n",
    "\n",
    "* Considerando todos los eventos y con lr=0.5 y 15 épocas: \n",
    "\n",
    "Para datos de entrenamiento: nDCG = 0.74\n",
    "Para datos de test: nDCG = 0.14\n",
    "\n",
    "Luego, los resultados muestran que aunque metricas como la precision y la recall mejoran incluyendo todos los eventos, el uso de estos eventos esta generando un overfitting pues mientras el valor de nDCG mejora considerablemente para los datos de entrenamiento (0.74), no lo hace para los datos de test (0.14). Luego, creemos que lo optimo es trabajar con las ultimas 96hs. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hito_3_de_Mentoria_MELI.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
